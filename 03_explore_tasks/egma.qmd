---
title: "LEVANTE Egma"
author: "Fionnuala O'Reilly"
toc: true
number-sections: true
highlight-style: pygments
format:
  html: 
    code-fold: true
---
Required packages

```{r}
#| echo: false

library("tidyverse")
library("glue")
library("here")
library("viridis")
library("purrr")
library("readr")
library("dplyr")
library("tidyr")
library("quarto")
library("forcats")
library("ggplot2")
```

Helper functions

```{r}
#| echo: false

source(here("02_score_data","02_fit_irt","irt_helpers.R"))
source(here::here("plot_settings.R"))
source(here("03_explore_tasks","explore_helper.R"))
```

Get egma data

```{r}
task_data_nested <- read_rds(here(glue("01_fetched_data/task_data_nested.rds")))
glimpse(task_data_nested)

egma <- load_task_data("math")
egma
```

Exploring item group

```{r}
base::table(egma$item_group)
```
Sum scores

```{r}
# 94 items
colnames(egma)

egma_runs <- egma |>
  group_by(site, user_id, run_id) |>
  summarise(
    correct = mean(correct, na.rm = TRUE),  
    age = mean(age, na.rm = TRUE),          
    n_items = n_distinct(item_uid) # how many unique items were completed
  )

egma_sum_scores <- ggplot(egma_runs, aes(x = age, y = correct)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "re")) +
  ylim(0, 1) +
  facet_wrap(~site) +
  labs(
    title = "Age-related accuracy, smoothed trends by site",
    x = "Age (years)",
    y = "Proportion correct",
    caption = "Note: Each point represents a participant run; smoothed trend by site"
  )

egma_sum_scores

ggsave(
  filename = here::here("03_explore_tasks", "Graphs", "egma_sum_scores.png"),
  plot = egma_sum_scores,
  width = 10, height = 6, dpi = 300
)
```

Accuracy on item groups

```{r}
egma_cat_runs <- egma |>
  group_by(site, user_id, run_id, item_group) |>
  summarise(
    correct = mean(correct, na.rm = TRUE),
    age = mean(age, na.rm = TRUE),
    n_items = n_distinct(item_uid),
    .groups = "drop"
  )

egma_counts <- egma_cat_runs |>
  group_by(site, item_group) |>
  summarise(n = n(), .groups = "drop")
```

Plot

```{r fig.height =8, fig.width = 10}

ggplot(egma_cat_runs, aes(x = age, y = correct)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  geom_text(data = egma_counts,
          aes(x = Inf, y = Inf, label = paste0("n = ", n)),
          hjust = -0.1, vjust = 1,
          size = 3, 
          inherit.aes = FALSE) +
  ylim(0, 1) +
  facet_grid(site ~ item_group) +
  labs(title = "EGMA accuracy by age, site, and category",
       x = "Age (years)",
       y = "Proportion correct")

```

Cleaner graph 

```{r}
egma_type <- egma |>
  group_by(site, user_id, run_id, item_group) |>
  summarise(correct = mean(correct, na.rm = TRUE),
            age = mean(age, na.rm = TRUE))

ggplot(egma_type, aes(x = age, y = correct, col = item_group)) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~site)
```

Difficulty

```{r}
# Proportion correct per item per site
item_difficulty <- egma |>
  group_by(site, item_uid) |>
  summarise(p_correct = mean(correct, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = site, values_from = p_correct)

# Man accuracy across sites
egma_difficulty_raw <- item_difficulty |>
  mutate(mean_accuracy = rowMeans(across(-item_uid), na.rm = TRUE))

# Reorder items from easiest to hardest
egma_difficulty_raw <- egma_difficulty_raw |>
  mutate(item_uid = fct_reorder(item_uid, mean_accuracy))
```

Plot

```{r fig.height=20, fig.width=10}
ggplot(egma_difficulty_raw, aes(x = item_uid, y = mean_accuracy, fill = mean_accuracy)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "EGMA item difficulty (easiest to hardest)",
    x = "Item (UID)",
    y = "Mean proportion correct",
    fill = "Accuracy"
  ) +
  ylim(0, 1) 

# Note: The 'easiest' items are based on the proportion of correct responses, which can be misleading if only a few participants attempted them. For example, two fraction items appear among the easiest, even though fractions are generally the most difficult categoryâ€”this is because the few participants who saw those items answered them correctly. IRT model accounts for this as it estimates item difficulty and discrimination while adjusting for participant ability.
```

Difficulty by item_group

```{r}
egma_groups <- egma |>
  select(item_uid, item_group) |>
  distinct()

egma_difficulty_grouped <- egma_difficulty_raw |>
  mutate(item_uid = as.character(item_uid)) |>
  left_join(egma_groups, by = "item_uid")

# Mean accuracy by item group
egma_group_summary <- egma_difficulty_grouped |>
  group_by(item_group) |>
  summarise(
    mean_accuracy = mean(mean_accuracy, na.rm = TRUE),
    n_items = n(),
    .groups = "drop"
  ) |>
  arrange(desc(mean_accuracy))

# Bar graph
ggplot(egma_group_summary, aes(x = fct_reorder(item_group, mean_accuracy), y = mean_accuracy, fill = mean_accuracy)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Average difficulty by item group (EGMA)",
    x = "Item group",
    y = "Mean proportion correct",
    fill = "Accuracy"
  ) +
  ylim(0, 1)

```

Box plot - spread of accuracy across categories

```{r}
ggplot(egma_difficulty_grouped, 
       aes(x = fct_reorder(item_group, mean_accuracy), y = mean_accuracy, fill = item_group)) +
  geom_boxplot() +
  coord_flip() +
  labs(
    title = "Distribution of item difficulty by group (EGMA)",
    x = "Item group", y = "Mean accuracy"
  ) 

# Dots
egma_accuracy_raw <- 
  ggplot(egma_difficulty_grouped, 
         aes(x = fct_reorder(item_group, mean_accuracy), y = mean_accuracy, 
             colour = item_group)) +
  geom_jitter() +
  coord_flip() +
  labs(
    title = "Distribution of item difficulty by group (EGMA)",
    x = "Item group", y = "Mean accuracy"
  ) 

ggsave(
  filename = here::here("03_explore_tasks", "Graphs", "egma_accuracy_raw.png"),
  plot = egma_accuracy_raw,
  width = 10,
  height = 6,
  dpi = 300
)
```

Reaction times

```{r}
summary(egma$rt_numeric)

egma_trimmed <- egma |> 
  filter(rt_numeric > 200, rt_numeric < 10000)

ggplot(egma_trimmed, aes(x = rt_numeric, fill = correct)) +
  facet_wrap(~site, scales = "free_y") +
  geom_histogram(binwidth = 100) +
  labs(
    title = "Histogram of reaction times by site",
    x = "Reaction time (ms)",
    y = "Count"
  )

# Check outliers
summary(egma$rt_numeric)
summary(egma_trimmed$rt_numeric)
```



# IRT 
Load IRT results
ToDo: fit bifactor model with each subtask

```{r}
# ToDo: update to use model_registry/math/ dir?
best_multigroup <- readRDS(here("02_scoring_outputs", "old", "irt_outputs", "multigroup_best_models.rds"))
multigroup_scores <- readRDS(here("02_scoring_outputs", "scores", "old", "multigroup_scores.rds"))

best_multigroup_coefs <- best_multigroup |>
  select(item_task, item_type, invariance_type, coefs) |>
  unnest(coefs)

best_coefs <- readRDS(here("02_scoring_outputs", "best_coefs.rds")) |> 
  filter(task=="math")
#all_coefs <- readRDS(here("02_scoring_outputs", "all_coefs.rds"))

```

Multigroup models

Developmental trends in egma math ability estimates by site

This plot shows how IRT-derived ability estimates (theta scores, i.e. estimated latent ability) from the Egma task vary with age across different sites.
```{r}

run_ages <- egma |>
  select(site, run_id, user_id, age) |>
  distinct()

multigroup_scores_egma <- multigroup_scores |>
  mutate(site = ifelse(site=="ca_pilot", "pilot_western_ca",
                       ifelse(site=="co_pilot", "pilot_uniandes_co", 
                              ifelse(site=="de_pilot", "pilot_mpieva_de", site)))) |>
  filter(item_task == "math", site != "us_pilot") |>
  select(site, item_task, user_id, run_id, metric_type, metric_value) |>
  left_join(run_ages)

glimpse(multigroup_scores_egma)

egma_irt <- ggplot(multigroup_scores_egma, aes(x = age, y = metric_value, col = site)) + 
  geom_point() + geom_smooth() +
  labs(
    title = "Developmental trends in EGMA ability by site",
    subtitle = "IRT-based theta estimates smoothed with GAM",
    x = "Age (years)",
    y = "Ability (IRT Theta Score)",
    colour = "Site"
  )

egma_irt
ggsave(
  filename = here::here("03_explore_tasks", "Graphs", "egma_irt.png"),
  plot = egma_irt,
  width = 6, height = 4, dpi = 300
)

```

Extract the coefficients  and filter for difficulty

```{r}
# Extract coefficients
egma_difficulty <- best_multigroup_coefs |> 
  filter(item_task == "math") |> 
  select(site, item, d)

# Compute average difficulty
egma_mean_difficulty <- egma_difficulty |> 
  group_by(item) |> 
  summarise(mean_d = mean(d, na.rm = TRUE), .groups = "drop")

# Join with item group
egma_groups <- egma |> 
  select(item_uid, item_group) |> 
  distinct() |> 
  mutate(item = glue("{item_uid}_1"))  

egma_difficulty_grouped <- left_join(egma_mean_difficulty, egma_groups, by = "item")

egma_difficulty_grouped |> filter(is.na(item_group))
```

Item difficulty by group

```{r}
ggplot(egma_difficulty_grouped, aes(x = fct_reorder(item_group, -mean_d), y = mean_d, fill = item_group)) +
  geom_boxplot(alpha = 0.8) +
  coord_flip() +
  labs(
    title = "Distribution of EGMA Item Difficulty by Item Group",
    x = "Item Group",
    y = "Mean IRT Difficulty"
  ) 

# Violin plot
ggplot(egma_difficulty_grouped, aes(x = fct_reorder(item_group, -mean_d), y = mean_d, fill = item_group)) +
  geom_violin(trim = FALSE, alpha = 0.7) +
  geom_boxplot(width = 0.1, fill = "white", outlier.size = 0.5) +
  coord_flip() +
  labs(
    title = "Distribution of EGMA item difficulty by group",
    x = "Item group",
    y = "Mean IRT difficulty"
  )

# Dots
ggplot(egma_difficulty_grouped, aes(x = fct_reorder(item_group, -mean_d), y = mean_d, colour = item_group)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.7) +
  coord_flip() +
  labs(
    title = "Item difficulty by group (individual points)",
    x = "Item group",
    y = "Mean IRT difficulty"
  )

```


# Number-to-line vs. line-to-number

```{r, eval=T}
# FixMe - egma_difficulty_grouped no longer includes site group, and site names are outdated
line_trials <- egma_difficulty_grouped |>
  filter(str_detect(item_uid, "line") | str_detect(item_uid, "slider")) |>
  separate(item_uid, into = c("item", "trial_type", "point","scale"), sep = "_") |>
  select(-mean_accuracy) |>
  pivot_longer(ca_pilot:de_pilot, names_to = "site", values_to = "correct") |>
  group_by(point, scale, site) |>
  mutate(match = n() == 2) |>
  filter(match) |>
  select(-item, -item_group, -match) |>
  ungroup() |>
  pivot_wider(names_from = "trial_type", values_from = "correct", id_cols = c("site", "point","scale"))


ggplot(line_trials, aes(x = line, y = slider)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  facet_wrap(~site)
```

Item parameters

```{r}
params <- best_multigroup_coefs |>
  filter(item_task == "math", str_detect(item, "line|slider")) |>
  separate(item, into = c("item", "trial_type", "point","scale","num"), sep = "_") |>
  filter(site == "de_pilot") |>
  select(item, trial_type, point, scale, d) |>
  pivot_wider(names_from = "trial_type", values_from = "d")

ggplot(params, aes(x = -line, y = -slider, col = scale)) + 
  geom_point()+ 
  # geom_smooth(method = "lm", aes(group = 1)) +
  geom_smooth(method = "lm", aes(group = 1),
              data = filter(params, !(scale=="100" & point == "9"))) +
  ggrepel::geom_text_repel(aes(label = point), size = 3) + 
  xlab("Line-to-number 4AFC difficulty") + 
  ylab("Number-to-line slider difficulty")

with(filter(params, !(scale=="100" & point == "9")), 
     cor.test(line, slider))
with(params,  cor.test(line, slider))
```

```{r, eval=F}
filter(egma, item_uid == "math_line_9_100") |> View()
```

# Examine Dimensionality

Note: 34% of responses are slower than 5s, yet have high accuracy. 12% are slower than 10s; I'm going to filter only trials >20s (2.6% of trials), and those <200ms.
We fit a 2PL model to these data, as well as exploratory 2- and 3-factor models, a CFA with each subtask fitted separately, and a bifactor model with each subtask, and a general factor. Model comparisons summarized below.

```{r, eval=F}
# exploratory 2-4 factor models, and bifactor model with each subtask
# nrow(egma |> filter(rt_numeric > 5000)) / nrow(egma) # 34% of responses are slower than 5s, & high accuracy

egma_sorted <- egma |> filter(rt_numeric > 200, rt_numeric < 20000) |>
  arrange(site, user_id, run_id, item_group, item_uid)

egma_wide <- egma_sorted |> select(site, user_id, age, run_id, item_uid, correct) |>
  pivot_wider(id_cols = c(site, user_id, run_id, age), names_from = item_uid, values_from = correct)

egma_wide_rt <- egma_sorted |> select(site, user_id, age, run_id, item_uid, rt_numeric) |>
  pivot_wider(id_cols = c(site, user_id, run_id, age), names_from = item_uid, values_from = rt_numeric)

egma_demo <- egma_wide |> select(site, user_id, age, run_id)
egma_dat <- egma_wide |> select(-site, -user_id, -age, -run_id)# |> data.matrix()
egma_dat_rt <- egma_wide_rt |> select(-site, -user_id, -age, -run_id)

one_value_cols <- names(egma_dat)[sapply(egma_dat, function(x) {
  length(unique(na.omit(x))) == 1
})]

egma_dat <- data.matrix(egma_dat |> select(-all_of(one_value_cols)))
rownames(egma_dat) = egma_demo$run_id

egma_dat_rt <- data.matrix(egma_dat_rt |> select(-all_of(one_value_cols)))
rownames(egma_dat_rt) = egma_demo$run_id

require("diffIRT")
mod_drt <- diffIRT(egma_dat_rt, egma_dat)
#mirt(egma_dat, 1, itemtype='2PL', verbose=TRUE,  technical=list(NCYCLES=3000))

mod_2pl <- mirt(egma_dat, 1, itemtype='2PL', verbose=TRUE,  technical=list(NCYCLES=3000))
mod_2pl_2f <- mirt(egma_dat, 2, itemtype='2PL', verbose=TRUE,  technical=list(NCYCLES=3000))
mod_2pl_3f <- mirt(egma_dat, 3, itemtype='2PL', verbose=TRUE,  technical=list(NCYCLES=3000))

egma_dat_sorted <- egma_dat[,order(colnames(egma_dat))]

cfa <- "add = 1-49
comp = 50-69
frac = 70-83
iden = 84-123
line = 124-194
miss = 195-214
mult = 215-256
slid = 257-295
sub = 296-345"
mod_cfa <- mirt(egma_dat_sorted, cfa, itemtype = "2PL", technical = list(NCYCLES=2000))

bifact <- "gen = 1-345
add = 1-49
comp = 50-69
frac = 70-83
iden = 84-123
line = 124-194
miss = 195-214
mult = 215-256
slid = 257-295
sub = 296-345"
mod_bif <- mirt(egma_dat_sorted, bifact, itemtype = "2PL", technical = list(NCYCLES=2000, MAXQUAD=60000))

save(mod_2pl, mod_2pl_2f, mod_2pl_3f, mod_cfa, mod_bif, 
     file=here::here("03_explore_tasks","math_models.Rdata"))
```

```{r}
load(here::here("03_explore_tasks","math_models.Rdata"))


bind_rows(anova(mod_2pl, mod_2pl_2f),  # AIC prefers 2d, BIC prefers 1d
          anova(mod_2pl_2f, mod_2pl_3f)[2,]) # AIC prefers 3d, BIC prefers 2d



bind_rows(anova(mod_2pl, mod_cfa),
          anova(mod_cfa, mod_bif)[2,], # 2pl 1d (and 2d) preferred
          anova(mod_cfa, mod_2pl_2f)[2,]) # AIC prefers bifactor, BIC favors CFA
```
The less conservative AIC prefers 3-factor over 2-factor or unidimensional models, but BIC prefers the simpler models. 
AIC prefers the bifactor model, while BIC prefers the CFA -- but the unidimensional 2PL is preferred by both criteria. 
