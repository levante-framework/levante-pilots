---
title: "LEVANTE Vocab"
author: "Fionnuala O'Reilly"
toc: true
number-sections: true
highlight-style: pygments
format:
  html: 
    code-fold: true
---

Required packages

```{r}

#| echo: false

library("tidyverse")
library("glue")
library("here")
library("viridis")
library("purrr")
library("readr")
library("dplyr")
library("tidyr")
library("quarto")
library("forcats")
library("ggplot2")
library("ggrepel")
library("broom")
library("purrr")

```

Helper functions

```{r}
#| echo: false

getwd()
source(here("03_summaries","plotting_helper.R"))
source(here("plot_settings.R"))
source(here("03_summaries","scores_helper.R"))
```

Get vocab data

```{r}
all_scores <- readRDS(here("02_scoring_outputs","scores","scores_combined.rds"))
colnames(all_scores)

vocab <- all_scores %>% 
  filter(item_task == "vocab")
```

Checking n's

```{r}
vocab |> 
  distinct(site, user_id) |> 
  count(site)

```

Get sum scores

```{r}

vocab_runs <- vocab |>
  filter(site != "us_pilot") |>
  group_by(site, user_id, run_id) |>
  summarise(
    correct = mean(correct, na.rm = TRUE),  
    age = mean(age, na.rm = TRUE),          
    n_items = n_distinct(item_uid)          
  )

vocab_sum_scores <- ggplot(vocab_runs, aes(x = age, y = correct)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "re")) +
  ylim(0, 1) +
  facet_wrap(~site) +
  labs(
    title = "Age-related accuracy, smoothed trends by site",
    x = "Age (years)",
    y = "Proportion correct",
    caption = "Note: Each point represents a participant run; smoothed trend by site"
  )
print(vocab_sum_scores)

ggsave(
  filename = here::here("03_explore_tasks", "Graphs", "vocab_sum_scores.png"),
  plot = vocab_sum_scores,
  width = 10,
  height = 6,
  dpi = 300
)

```

Examining least and most difficult items

```{r}
# Calculate item-level accuracy
item_accuracy <- vocab |>
  group_by(item_uid) |>
  summarise(proportion_correct = mean(correct, na.rm = TRUE)) |>
  arrange(proportion_correct) |>
  mutate(item_rank = row_number())

```

Plot

```{r fig.height =14, fig.width = 8}

# Plot all items
ggplot(item_accuracy, aes(x = reorder(item_uid, proportion_correct), y = proportion_correct)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Proportion Correct by Vocabulary Item (All Items)",
    x = "Vocabulary Item",
    y = "Proportion Correct"
  ) 

# Note this doesn't take account of the difficulty of items as in the IRT models.

```

Subset of items (random, every 5th)

```{r}
# Filter every 5th item
sampled_items <- item_accuracy |>
  filter(item_rank %% 5 == 0)

# Plot sampled items
ggplot(sampled_items, aes(x = reorder(item_uid, proportion_correct), y = proportion_correct)) +
  geom_col() +
  coord_flip() +
    labs(
    title = "Proportion Correct (Sampled Vocabulary Items)",
    x = "Vocabulary Item (every 5th)",
    y = "Proportion Correct"
  ) 

```

By age

```{r}

# Create age brackets
vocab_binned <- vocab |>
  mutate(age_bracket = cut(age, c(4, 7, 9, 13), include.lowest = TRUE)) |>
  filter(!is.na(age_bracket))

summary(vocab$age)
table(is.na(vocab$age))

# Accuracy by age
item_accuracy_by_bracket <- vocab_binned |>
  group_by(age_bracket, item_uid) |>
  summarise(
    proportion_correct = mean(correct, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

# Top 10 easiest and 10 hardest per age bin 
easiest_hardest_by_bracket <- item_accuracy_by_bracket |>
  group_by(age_bracket) |>
  arrange(proportion_correct) |>
  mutate(rank = row_number()) |>
  filter(rank <= 10 | rank > (n() - 10)) |>
  distinct(age_bracket, item_uid, .keep_all = TRUE)

# Plot (without sample size labels)
ggplot(easiest_hardest_by_bracket, aes(x = reorder(item_uid, proportion_correct), y = proportion_correct, fill = age_bracket)) +
  geom_col(show.legend = FALSE) +
  scale_fill_viridis_d() +
  coord_flip() +
  facet_wrap(~ age_bracket, scales = "free_y") +
  labs(
    title = "Easiest and Hardest Vocabulary Items by Age Bracket",
    x = "Vocabulary Item",
    y = "Proportion Correct"
  ) +
  ylim(0, 1.1) +
  theme_minimal()


```

By country

```{r}

# Accuracy per item by site
item_accuracy_by_site <- vocab |>
  filter(site %in% c("ca_pilot", "co_pilot", "de_pilot")) |>
  group_by(site, item_uid) |>
  summarise(
    proportion_correct = mean(correct, na.rm = TRUE),
    n = n(),  # sample size
    .groups = "drop"
  )

# Top 10 easiest and hardest items per site
easiest_hardest_by_site <- item_accuracy_by_site |>
  group_by(site) |>
  arrange(proportion_correct) |>
  mutate(rank = row_number())
  #filter(rank <= 10 | rank > (n() - 10))

```

Plot

```{r fig.height =14, fig.width = 8}
# Plot 
ggplot(easiest_hardest_by_site, aes(x = reorder(item_uid, proportion_correct), y = proportion_correct, fill = site)) +
  geom_col(show.legend = FALSE) +
  geom_text(aes(label = glue::glue("{n}")),
            hjust = -0.1, size = 1.5) +
  coord_flip() +
  scale_fill_viridis_d() +
  facet_wrap(~ site, scales = "free_y") +
  labs(
    title = "Easiest and Hardest Vocabulary Items by Country",
    x = "Vocabulary Item",
    y = "Proportion Correct"
  ) +
  ylim(0, 1.05) +
  theme_minimal()

```

Examining item accuracy (proportion correct) across sites, adjusting for age

```{r}

# Safe GLM wrapper to skip items that crash (e.g. single-site items)
safe_glm <- purrr::possibly(
  function(df) glm(correct ~ site + age, data = df, family = binomial()),
  otherwise = NULL
)

# Fit per-item logistic models and extract site effects
item_models <- vocab %>%
  filter(site %in% c("ca_pilot", "co_pilot", "de_pilot")) %>%
  group_by(item_uid) %>%
  nest() %>%
  mutate(
    model = map(data, safe_glm),
    tidied = map(model, ~ if (!is.null(.x)) tidy(.x) else tibble())
  ) %>%
  unnest(tidied)

# Extract site effects (excluding intercept and age)
site_effects <- item_models %>%
  filter(term %in% c("siteco_pilot", "sitede_pilot")) %>%
  mutate(abs_estimate = abs(estimate))

# Get top 20 items with largest site differences (adjusted for age)
top_items_adj <- site_effects %>%
  group_by(item_uid) %>%
  summarise(site_diff = max(abs_estimate), .groups = "drop") %>%
  arrange(desc(site_diff)) %>%
  slice_head(n = 20)

# Bring in raw accuracy data for plotting
top_items_accuracy <- item_accuracy_by_site %>%
  filter(item_uid %in% top_items_adj$item_uid)

# Plot raw accuracy for these items (to visualize effect scale)
ggplot(top_items_accuracy, aes(x = proportion_correct, y = reorder(item_uid, proportion_correct), color = site)) +
  geom_point(size = 3) +
  geom_line(aes(group = item_uid), color = "gray70", linewidth = 0.6) +
  scale_color_viridis_d() +
  labs(
    title = "Top 20 vocabulary items with cross-site accuracy gaps (age-adjusted)",
    x = "Proportion Correct",
    y = "Vocabulary Item"
  ) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "bottom")


```

Same graph, re-ordered by the size of the difference between sites

```{r}
# Vector of items ordered by difficult gap across sites 
item_order <- top_items_adj %>%
  arrange(desc(site_diff)) %>%
  pull(item_uid)

# Reorder factor levels in accuracy data
top_items_accuracy$item_uid <- factor(top_items_accuracy$item_uid, levels = item_order)

# Plot again
item_site_diff <- ggplot(top_items_accuracy, aes(x = proportion_correct, y = item_uid, color = site)) +
  geom_point(size = 3) +
  geom_line(aes(group = item_uid), color = "gray70", linewidth = 0.6) +
  scale_color_viridis_d() +
  labs(
  title = "Top 20 vocabulary items with site differences (age-adjusted)",
  subtitle = "Ranked by age-adjusted site effects from logistic regression; plotted using raw accuracy",
  x = "Proportion Correct",
  y = "Vocabulary Item"
) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "bottom")

print(item_site_diff)

# The items near the top of the plot had the largest model-estimated site effects, after adjusting for age — not necessarily the largest raw proportion gaps.

# save
ggsave(
  filename = here::here("03_explore_tasks", "Graphs", "item_site_diff.png"),
  plot = item_site_diff,
  width = 6,
  height = 4,
  dpi = 300
)



```

Load IRT results

```{r}


coefs <- readRDS(here::here("02_scoring_outputs", "best_coefs.rds"))
colnames(coefs)
table(coefs$task)
table(coefs$group)
table(coefs$g)
table(coefs$u)
table(coefs$d)
                 

```

Plot item difficulties
```{r diff plot, fig.width=30, fig.height=30}

library(dplyr)
library(ggplot2)
library(forcats)

vocab_only <- coefs %>%
  filter(task == "vocab") %>%                
  mutate(item = fct_reorder(item, -d, .fun = mean, .na_rm = TRUE))

ggplot(vocab_only, aes(x = item, y = d)) +
  geom_hline(yintercept = 0, linetype = 2, linewidth = 0.2) +
  geom_point() +
  coord_flip() +
  labs(x = "Vocab item", y = "Difficulty (d, logit)", title = "Vocabulary difficulties") +
  theme_minimal(base_size = 12)


```

Hardest and easiest

```{r hardest-easiest}

vocab_avg <- coefs %>%
  filter(task == "vocab") %>%
  group_by(item) %>%
  summarise(d_mean = mean(-d, na.rm = TRUE), n_rows = dplyr::n(), .groups = "drop") %>%
  arrange(d_mean)

easiest_15 <- slice_head(vocab_avg, n = 15)   
hardest_15 <- slice_tail(vocab_avg, n = 15)   

easiest_15
hardest_15


```

Difficulty across site

```{r fig.height =10, fig.width = 10}
library(dplyr)
library(forcats)
library(ggplot2)
library(stringr)

# coefficients table
vocab <- coefs %>%
  filter(task %in% c("vocab","Vocabulary"),
         model_set == "by_language",
         group == "all",
         subset %in% c("de","en","es"))

# top/bottom N items for a given subset
pick_items <- function(df, subset_code, n = 20, hardest = TRUE) {
  df %>%
    filter(subset == subset_code) %>%
    group_by(item) %>%
    summarise(d = mean(d, na.rm = TRUE), .groups = "drop") %>%
    { if (hardest) slice_max(., d, n = n) else slice_min(., d, n = n) } %>%
    mutate(item = fct_reorder(item, d))
}

# Plot function
plot_items <- function(df_items, title) {
  ggplot(df_items, aes(item, -d)) +
    geom_hline(yintercept = 0, linetype = 2, linewidth = 0.05) +
    geom_point() +
    coord_flip() +
    labs(x = "Vocabulary item", y = "Difficulty (d, logit)", title = title) +
    theme_minimal(base_size = 12)
}

# plot Columbia only
co_hard20 <- pick_items(vocab, "es", n = 20, hardest = TRUE)  
p_co_hard <- plot_items(co_hard20, "Top 20 hardest vocabulary items — Colombia")
p_co_hard



```

20 most difficult vocab items - Columbia only.

```{r}

library(dplyr)
library(ggplot2)
library(forcats)

# collapse to one difficulty per item (mean across any repeats)
co_coefs_item <- co_coefs %>%
  group_by(item) %>%
  summarise(d = mean(d, na.rm = TRUE), .groups = "drop")

# take the 20 hardest (largest d)
hard20 <- co_coefs_item %>%
  slice_max(d, n = 20) %>%
  mutate(item = fct_reorder(item, d))

# plot
ggplot(hard20, aes(item, -d)) +
  geom_hline(yintercept = 0, linetype = 2, linewidth = 0.2) +
  geom_point() +
  coord_flip() +
  labs(x = "Vocabulary item", y = "Difficulty (d, logit)",
       title = "Top 20 hardest vocabulary items — Colombia") +
  theme_minimal(base_size = 12)


```

Plot

```{r}

# Change labels
library(stringr)

coefs_top_items <- coefs_top_items %>%
  mutate(
    item_clean = item |>
      str_remove("^vocab_") |>          # remove 'vocab_'
      str_remove("_[0-9]+$") |>         # remove trailing '_1', '_2', etc.
      str_replace_all("_", " ")         # optional: replace underscores with spaces (or remove this line if you want to keep compound words as-is)
  )

# Order itmes so the ones with the greatest difference appear first
item_order <- coefs_top_items %>%
  group_by(item_clean) %>%
  summarise(var_d = max(d) - min(d)) %>%
  arrange(desc(var_d)) %>%
  pull(item_clean)

coefs_top_items$item_clean <- factor(coefs_top_items$item_clean, levels = item_order)

# Plot
ggplot(coefs_top_items, aes(x = -d, y = a1, color = site, label = item_clean)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_text_repel(size = 3, max.overlaps = 20) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray70") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray70") +
  labs(
    title = "Vocabulary Item Difficulty vs. Discrimination (Top 20 Most Variable Items)",
    x = "Item Difficulty (d)",
    y = "Item Discrimination (a)"
  ) +
  scale_color_viridis_d() +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom")

```